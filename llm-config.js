// ============================================
// LLM å¤§æ¨¡åž‹é…ç½®æ–‡ä»¶
// æ‰€æœ‰ä¸Žå¤§æ¨¡åž‹ç›¸å…³çš„é…ç½®é›†ä¸­åœ¨æ­¤ï¼Œä¸è¦å†™æ­»åœ¨ä»£ç ä¸­
// ============================================

const LLM_CONFIG = {

  // ------------------------------------------
  // å½“å‰ä½¿ç”¨çš„æ¨¡åž‹ä¾›åº”å•†ï¼ˆåˆ‡æ¢ä¾›åº”å•†åªéœ€æ”¹è¿™é‡Œï¼‰
  // å¯é€‰å€¼: 'moonshot', 'openai', 'deepseek', 'zhipu', 'minimax', 'custom'
  // ------------------------------------------
  provider: 'minimax',

  // ------------------------------------------
  // å„ä¾›åº”å•†é¢„è®¾é…ç½®
  // ------------------------------------------
  providers: {

    moonshot: {
      name: 'Moonshot / Kimi',
      apiUrl: 'https://api.moonshot.cn/v1/chat/completions',
      models: [
        { id: 'kimi-k2.5',        name: 'Kimi K2.5ï¼ˆæœ€ä¾¿å®œï¼‰',  contextLength: 128000 },
        { id: 'moonshot-v1-8k',   name: 'V1 8K',               contextLength: 8000   },
        { id: 'moonshot-v1-32k',  name: 'V1 32K',              contextLength: 32000  },
        { id: 'moonshot-v1-128k', name: 'V1 128K',             contextLength: 128000 }
      ],
      defaultModel: 'kimi-k2.5'
    },

    openai: {
      name: 'OpenAI / ChatGPT',
      apiUrl: 'https://api.openai.com/v1/chat/completions',
      models: [
        { id: 'gpt-4o-mini',  name: 'GPT-4o Miniï¼ˆä¾¿å®œï¼‰', contextLength: 128000 },
        { id: 'gpt-4o',       name: 'GPT-4o',             contextLength: 128000 },
        { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo',     contextLength: 16000  }
      ],
      defaultModel: 'gpt-4o-mini'
    },

    deepseek: {
      name: 'DeepSeek',
      apiUrl: 'https://api.deepseek.com/v1/chat/completions',
      models: [
        { id: 'deepseek-chat',     name: 'DeepSeek Chat',     contextLength: 64000 },
        { id: 'deepseek-reasoner', name: 'DeepSeek Reasoner', contextLength: 64000 }
      ],
      defaultModel: 'deepseek-chat'
    },

    zhipu: {
      name: 'æ™ºè°± / GLM',
      apiUrl: 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
      models: [
        { id: 'glm-4-flash', name: 'GLM-4 Flashï¼ˆå…è´¹ï¼‰', contextLength: 128000 },
        { id: 'glm-4',       name: 'GLM-4',              contextLength: 128000 }
      ],
      defaultModel: 'glm-4-flash'
    },

    minimax: {
      name: 'MiniMax',
      apiUrl: 'https://api.minimax.chat/v1/text/chatcompletion_v2',
      models: [
        { id: 'MiniMax-M2.5', name: 'MiniMax-M2.5', contextLength: 100000 }
      ],
      defaultModel: 'MiniMax-M2.5'
    },

    custom: {
      name: 'è‡ªå®šä¹‰ï¼ˆå…¼å®¹OpenAIæ ¼å¼ï¼‰',
      apiUrl: '',
      models: [
        { id: 'custom-model', name: 'è‡ªå®šä¹‰æ¨¡åž‹', contextLength: 8000 }
      ],
      defaultModel: 'custom-model'
    }
  },

  // ------------------------------------------
  // å½“å‰é€‰æ‹©çš„æ¨¡åž‹IDï¼ˆç•™ç©ºåˆ™ä½¿ç”¨ä¾›åº”å•†çš„defaultModelï¼‰
  // ------------------------------------------
  model: '',

  // ------------------------------------------
  // API Keyï¼ˆé€šè¿‡è®¾ç½®é¡µé¢é…ç½®ï¼Œæ­¤å¤„ä¸è¦å†™æ­»ï¼‰
  // ------------------------------------------
  apiKey: '',

  // ------------------------------------------
  // ç”Ÿæˆå‚æ•°
  // ------------------------------------------
  generation: {
    temperature: 1.0,       // åˆ›é€ æ€§ 0-1ï¼Œè¶Šé«˜è¶Šæœ‰åˆ›æ„
    maxTokens: 2000,        // æœ€å¤§è¾“å‡ºtokenæ•°
    maxInputChars: 6000     // è¾“å…¥å†…å®¹æœ€å¤§å­—ç¬¦æ•°ï¼ˆç•™ä½™é‡ç»™æç¤ºè¯ï¼‰
  },

  // ------------------------------------------
  // ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯è‡ªå®šä¹‰æ€»ç»“é£Žæ ¼ï¼‰
  // ------------------------------------------
  systemPrompt: `ä½ æ˜¯ä¸€ä¸ªå­¦ä¹ æ€»ç»“åŠ©æ‰‹ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€å¤©ä¸­ä¸Žå„ç§AIåŠ©æ‰‹çš„å¯¹è¯è®°å½•ã€‚
è¯·ä½ åˆ†æžè¿™äº›å¯¹è¯ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´ã€ç»“æž„åŒ–çš„æ¯æ—¥å­¦ä¹ æ€»ç»“ã€‚

æ€»ç»“è¦æ±‚ï¼š
1. ðŸŽ¯ ä»Šæ—¥ä¸»é¢˜ï¼šåˆ—å‡ºä»Šå¤©è®¨è®ºçš„ä¸»è¦è¯é¢˜ï¼ˆ2-5ä¸ªï¼‰
2. ðŸ’¡ å…³é”®æ”¶èŽ·ï¼šä»Žå¯¹è¯ä¸­æç‚¼å‡ºæœ€é‡è¦çš„çŸ¥è¯†ç‚¹æˆ–å‘çŽ°ï¼ˆ3-8æ¡ï¼‰
3. ðŸ”§ å®žè·µè¦ç‚¹ï¼šæ€»ç»“å¯ä»¥ç«‹å³åº”ç”¨çš„æŠ€å·§æˆ–æ–¹æ³•
4. ðŸ“Š å­¦ä¹ æ¦‚å†µï¼šç®€è¦ç»Ÿè®¡ï¼ˆå¯¹è¯æ•°é‡ã€æ¶‰åŠå¹³å°ã€ä¸»è¦é¢†åŸŸï¼‰
5. ðŸš€ æ˜Žæ—¥å»ºè®®ï¼šåŸºäºŽä»Šå¤©çš„å­¦ä¹ ï¼Œç»™å‡ºåŽç»­å­¦ä¹ å»ºè®®

éœ€è¦ï¼šä¸­æ–‡å›žç­”ã€éžå¸¸ç®€æ´ã€æ ¼å¼æ¸…æ™°ï¼Œä½¿ç”¨emojiè®©æ€»ç»“æ›´ç”ŸåŠ¨ã€‚æ¯ä¸ªéƒ¨åˆ†ç”¨ç®€æ´æœ‰åŠ›çš„è¯­è¨€ã€‚`
};

// ------------------------------------------
// è¾…åŠ©æ–¹æ³•ï¼šèŽ·å–å½“å‰ç”Ÿæ•ˆçš„å®Œæ•´é…ç½®
// ------------------------------------------

/**
 * èŽ·å–å½“å‰ä¾›åº”å•†é…ç½®
 */
function getCurrentProvider() {
  return LLM_CONFIG.providers[LLM_CONFIG.provider] || LLM_CONFIG.providers.moonshot;
}

/**
 * èŽ·å–å½“å‰ä½¿ç”¨çš„æ¨¡åž‹ID
 */
function getCurrentModel() {
  const provider = getCurrentProvider();
  return LLM_CONFIG.model || provider.defaultModel;
}

/**
 * èŽ·å–å½“å‰æ¨¡åž‹çš„ä¸Šä¸‹æ–‡é•¿åº¦
 */
function getCurrentContextLength() {
  const provider = getCurrentProvider();
  const modelId = getCurrentModel();
  const modelInfo = provider.models.find(m => m.id === modelId);
  return modelInfo ? modelInfo.contextLength : 8000;
}

/**
 * èŽ·å–API URL
 */
function getApiUrl() {
  const provider = getCurrentProvider();
  return provider.apiUrl;
}

/**
 * èŽ·å–API Key
 */
function getApiKey() {
  return LLM_CONFIG.apiKey;
}

/**
 * æ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦è®¡ç®—æœ€å¤§è¾“å…¥å­—ç¬¦æ•°
 * é¢„ç•™ 30% ç»™ç³»ç»Ÿæç¤ºè¯ + è¾“å‡º
 */
function getMaxInputChars() {
  const contextLen = getCurrentContextLength();
  // ç²—ç•¥æŒ‰1ä¸ªtokenâ‰ˆ1.5ä¸ªä¸­æ–‡å­—ç¬¦ä¼°ç®—
  return Math.floor(contextLen * 1.5 * 0.7);
}

/**
 * ä»ŽstorageåŠ è½½ç”¨æˆ·ä¿å­˜çš„LLMé…ç½®ï¼Œè¦†ç›–é»˜è®¤å€¼
 */
async function loadLLMConfigFromStorage() {
  return new Promise(resolve => {
    chrome.storage.local.get(['llmConfig'], result => {
      if (result.llmConfig) {
        const saved = result.llmConfig;
        if (saved.provider) LLM_CONFIG.provider = saved.provider;
        if (saved.model) LLM_CONFIG.model = saved.model;
        if (saved.apiKey) LLM_CONFIG.apiKey = saved.apiKey;
        if (saved.apiUrl) {
          // è‡ªå®šä¹‰API URL
          const provider = getCurrentProvider();
          if (provider) provider.apiUrl = saved.apiUrl;
        }
        if (saved.systemPrompt) LLM_CONFIG.systemPrompt = saved.systemPrompt;
        if (saved.generation) {
          Object.assign(LLM_CONFIG.generation, saved.generation);
        }
      }
      resolve(LLM_CONFIG);
    });
  });
}

/**
 * ä¿å­˜LLMé…ç½®åˆ°storage
 */
async function saveLLMConfigToStorage(config) {
  return new Promise(resolve => {
    chrome.storage.local.set({ llmConfig: config }, resolve);
  });
}

